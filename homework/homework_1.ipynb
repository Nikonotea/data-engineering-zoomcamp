{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cf109af9-61f9-4a58-87da-83036b77608b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0c12f339-51de-4117-9c8f-8561a25010e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "614333fb-936c-4044-85fd-c1cad9174857",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ff764f3c-b520-4c9a-9a34-29232e13c1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_tripdata_csv = 'C:/Users/me/Documents/green_tripdata_2019-10.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "934096b0-69e4-4fef-81cd-7ab264c6b448",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_taxi_zone_csv = 'C:/Users/me/Documents/taxi_zone_lookup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ee6a6942-f715-42c6-b9a5-6879b430a050",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_name = 'green_tripdata'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "b64698cb-6963-467f-80c4-3d44e2705cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('postgresql://postgres:postgres@localhost:5433/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "407b81e6-99d2-4d16-b1d2-24b497042dcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.base.Connection at 0x2b23dd96a50>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "42115c67-589f-4b8d-a12c-266633b7c932",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path_to_tripdata_csv, nrows=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4a85e568-f4bc-4c7d-946f-a469d098496e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lpep_pickup_datetime'] = pd.to_datetime(df['lpep_pickup_datetime']).dt.tz_localize('America/New_York').dt.tz_convert('UTC')\n",
    "df['lpep_dropoff_datetime'] = pd.to_datetime(df['lpep_dropoff_datetime']).dt.tz_localize('America/New_York').dt.tz_convert('UTC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "9c86c1d4-4661-4138-af3d-d3cb03d1624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE green_tripdata (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\tlpep_pickup_datetime TIMESTAMP WITH TIME ZONE, \n",
      "\tlpep_dropoff_datetime TIMESTAMP WITH TIME ZONE, \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"RatecodeID\" BIGINT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpassenger_count BIGINT, \n",
      "\ttrip_distance FLOAT(53), \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\tehail_fee FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tpayment_type BIGINT, \n",
      "\ttrip_type BIGINT, \n",
      "\tcongestion_surcharge FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df, name=df_name, con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "523b0641-8c5e-430c-a7b4-6210f511886e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iter = pd.read_csv(path_to_tripdata_csv, iterator=True, chunksize=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c691ea22-8496-4c24-a7cb-0c5f5438e128",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = next(df_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "870ffd9c-0507-4d73-9dd6-5967d301b81b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f306d182-f776-42c3-9403-9a145c40db85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=0).to_sql(name=df_name, con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "d9938607-9c1f-4665-8668-4ab72b9d3d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 422 ms\n",
      "Wall time: 1.06 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df.to_sql(name=df_name, con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3e6b20a1-2a90-45e9-87ac-95a89cd88d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "0c521db7-579d-46d5-83b8-90355696c896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted another chunk, took 0.922 second\n",
      "inserted another chunk, took 0.945 second\n",
      "inserted another chunk, took 0.860 second\n",
      "inserted another chunk, took 0.812 second\n",
      "inserted another chunk, took 0.716 second\n",
      "inserted another chunk, took 0.715 second\n",
      "inserted another chunk, took 0.714 second\n",
      "inserted another chunk, took 0.747 second\n",
      "inserted another chunk, took 0.723 second\n",
      "inserted another chunk, took 0.739 second\n",
      "inserted another chunk, took 0.785 second\n",
      "inserted another chunk, took 0.753 second\n",
      "inserted another chunk, took 0.732 second\n",
      "inserted another chunk, took 0.967 second\n",
      "inserted another chunk, took 0.736 second\n",
      "inserted another chunk, took 0.714 second\n",
      "inserted another chunk, took 1.198 second\n",
      "inserted another chunk, took 0.973 second\n",
      "inserted another chunk, took 1.136 second\n",
      "inserted another chunk, took 1.059 second\n",
      "inserted another chunk, took 1.018 second\n",
      "inserted another chunk, took 0.721 second\n",
      "inserted another chunk, took 0.701 second\n",
      "inserted another chunk, took 0.757 second\n",
      "inserted another chunk, took 0.783 second\n",
      "inserted another chunk, took 0.714 second\n",
      "inserted another chunk, took 0.719 second\n",
      "inserted another chunk, took 1.013 second\n",
      "inserted another chunk, took 1.590 second\n",
      "inserted another chunk, took 1.491 second\n",
      "inserted another chunk, took 1.437 second\n",
      "inserted another chunk, took 1.215 second\n",
      "inserted another chunk, took 1.224 second\n",
      "inserted another chunk, took 1.448 second\n",
      "inserted another chunk, took 1.101 second\n",
      "inserted another chunk, took 0.731 second\n",
      "inserted another chunk, took 0.747 second\n",
      "inserted another chunk, took 0.832 second\n",
      "inserted another chunk, took 0.741 second\n",
      "inserted another chunk, took 0.666 second\n",
      "inserted another chunk, took 0.683 second\n",
      "inserted another chunk, took 0.616 second\n",
      "inserted another chunk, took 0.732 second\n",
      "inserted another chunk, took 0.786 second\n",
      "inserted another chunk, took 1.066 second\n",
      "inserted another chunk, took 0.907 second\n",
      "inserted another chunk, took 0.477 second\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[154], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m#try:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m         t_start \u001b[38;5;241m=\u001b[39m time()\n\u001b[1;32m----> 4\u001b[0m         df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m         df\u001b[38;5;241m.\u001b[39mlpep_pickup_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mlpep_pickup_datetime)\n\u001b[0;32m      6\u001b[0m         df\u001b[38;5;241m.\u001b[39mlpep_dropoff_datetime \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mlpep_dropoff_datetime)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1843\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1985\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m   1984\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[1;32m-> 1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1923\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1916\u001b[0m nrows \u001b[38;5;241m=\u001b[39m validate_integer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnrows\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrows)\n\u001b[0;32m   1917\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1918\u001b[0m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[0;32m   1919\u001b[0m     (\n\u001b[0;32m   1920\u001b[0m         index,\n\u001b[0;32m   1921\u001b[0m         columns,\n\u001b[0;32m   1922\u001b[0m         col_dict,\n\u001b[1;32m-> 1923\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[0;32m   1924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[0;32m   1925\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1926\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:234\u001b[0m, in \u001b[0;36mCParserWrapper.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlow_memory:\n\u001b[1;32m--> 234\u001b[0m         chunks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[0;32m    236\u001b[0m         data \u001b[38;5;241m=\u001b[39m _concatenate_chunks(chunks)\n",
      "File \u001b[1;32mparsers.pyx:863\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True: \n",
    "    #try:\n",
    "        t_start = time()\n",
    "        df = next(df_iter)\n",
    "        df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "        df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "        df.to_sql(name=df_name, con=engine, if_exists='append')\n",
    "        t_end = time()\n",
    "        print('inserted another chunk, took %.3f second' % (t_end - t_start))\n",
    "    #except StopIteration:\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0eb0b4c8-9025-49fa-b74e-2d8d42895fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_zones = pd.read_csv(path_to_taxi_zone_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0f2891b1-595b-4e98-9773-7c9d355bd6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LocationID</th>\n",
       "      <th>Borough</th>\n",
       "      <th>Zone</th>\n",
       "      <th>service_zone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EWR</td>\n",
       "      <td>Newark Airport</td>\n",
       "      <td>EWR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Queens</td>\n",
       "      <td>Jamaica Bay</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Bronx</td>\n",
       "      <td>Allerton/Pelham Gardens</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Manhattan</td>\n",
       "      <td>Alphabet City</td>\n",
       "      <td>Yellow Zone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Staten Island</td>\n",
       "      <td>Arden Heights</td>\n",
       "      <td>Boro Zone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   LocationID        Borough                     Zone service_zone\n",
       "0           1            EWR           Newark Airport          EWR\n",
       "1           2         Queens              Jamaica Bay    Boro Zone\n",
       "2           3          Bronx  Allerton/Pelham Gardens    Boro Zone\n",
       "3           4      Manhattan            Alphabet City  Yellow Zone\n",
       "4           5  Staten Island            Arden Heights    Boro Zone"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f0cd7221-bca7-4d01-a49c-e6d69e917b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "265"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_zones.to_sql(name='zones', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "132b06f6-2b37-4b8e-b945-1658e5adf4c2",
   "metadata": {},
   "source": [
    "## Question 3. Trip Segmentation Count\n",
    "\n",
    "During the period of October 1st 2019 (inclusive) and November 1st 2019 (exclusive), how many trips, **respectively**, happened:\n",
    "1. Up to 1 mile\n",
    "2. In between 1 (exclusive) and 3 miles (inclusive),\n",
    "3. In between 3 (exclusive) and 7 miles (inclusive),\n",
    "4. In between 7 (exclusive) and 10 miles (inclusive),\n",
    "5. Over 10 miles "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "93a4e2b6-190a-4a2a-af72-b3946709478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    COUNT(CASE WHEN t.trip_distance <= 1 THEN 1 END) AS \"Up to 1 mile\",\n",
    "    COUNT(CASE WHEN t.trip_distance > 1 AND t.trip_distance <= 3 THEN 1 END) AS \"Between 1 and 3 miles\",\n",
    "    COUNT(CASE WHEN t.trip_distance > 3 AND t.trip_distance <= 7 THEN 1 END) AS \"Between 3 and 7 miles\",\n",
    "    COUNT(CASE WHEN t.trip_distance > 7 AND t.trip_distance <= 10 THEN 1 END) AS \"Between 7 and 10 miles\",\n",
    "    COUNT(CASE WHEN t.trip_distance > 10 THEN 1 END) AS \"Over 10 miles\"\n",
    "FROM\n",
    "    green_tripdata t\n",
    "WHERE\n",
    "    CAST(t.lpep_dropoff_datetime AS DATE) >= '2019-10-01'\n",
    "    AND CAST(t.lpep_dropoff_datetime AS DATE) < '2019-11-01';\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "55a7d8e1-88d8-4bb9-80d2-fb50a14b7e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "e89d20e2-c595-4122-8f67-000745bc995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transposed = df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5573a959-31a4-4aec-8fe2-e6005ed40e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transposed.columns = ['Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "277f1cf5-5fa2-4392-9e50-6f0eef27f1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Count\n",
      "Up to 1 mile            104802\n",
      "Between 1 and 3 miles   198924\n",
      "Between 3 and 7 miles   109603\n",
      "Between 7 and 10 miles   27678\n",
      "Over 10 miles            35189\n"
     ]
    }
   ],
   "source": [
    "print(df_transposed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8105312c-8915-4785-9110-3294883a7634",
   "metadata": {},
   "source": [
    "## Question 4. Longest trip for each day\n",
    "Which was the pick up day with the longest trip distance?\n",
    "\n",
    "Use the pick up time for your calculations.\n",
    "\n",
    "Tip: For every day, we only care about one single trip with the longest distance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "86cc7ec3-2f07-4888-9e30-b19ecf75bb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    CAST(lpep_pickup_datetime AS DATE) AS pickup_day,\n",
    "    MAX(trip_distance) AS max_distance\n",
    "FROM\n",
    "    green_tripdata\n",
    "WHERE\n",
    "    lpep_pickup_datetime >= '2019-10-01'\n",
    "    AND lpep_pickup_datetime < '2019-11-01'\n",
    "GROUP BY\n",
    "    pickup_day\n",
    "ORDER BY\n",
    "    max_distance DESC\n",
    "LIMIT 1;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "a44da59a-690c-4d55-98f5-86fe2b25f5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "4807d0b9-7bd3-43cc-81d1-7d3e77e6be6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pickup_day  max_distance\n",
      "0  2019-10-31        515.89\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac533dd2-1b40-462a-ba17-e007a0b35216",
   "metadata": {},
   "source": [
    "## Question 5. Three biggest pickup zones\n",
    "\n",
    "Which were the top pickup locations with over 13,000 in\n",
    "`total_amount` (across all trips) for 2019-10-18?\n",
    "\n",
    "Consider only `lpep_pickup_datetime` when filtering by date.\n",
    " \n",
    "- East Harlem North, East Harlem South, Morningside Heights\n",
    "- East Harlem North, Morningside Heights\n",
    "- Morningside Heights, Astoria Park, East Harlem South\n",
    "- Bedford, East Harlem North, Astoria Park"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "2e9dc54b-af91-4795-a094-5fa272a31978",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    zpu.\"Zone\",\n",
    "    SUM(total_amount) AS total_sum,\n",
    "    COUNT(1) AS \"count\"\n",
    "FROM\n",
    "    green_tripdata t\n",
    "JOIN\n",
    "    zones zpu ON t.\"PULocationID\" = zpu.\"LocationID\"\n",
    "WHERE\n",
    "    CAST(lpep_pickup_datetime AS DATE) = '2019-10-18'\n",
    "GROUP BY\n",
    "    zpu.\"Zone\"\n",
    "HAVING\n",
    "    SUM(total_amount) > 13000\n",
    "ORDER BY\n",
    "    total_sum DESC;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "9bc48e57-6cfd-487d-a597-7e9c7a968549",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "fa5d07c2-87f1-4b84-b624-f644eabd569c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Zone  total_sum  count\n",
      "0    East Harlem North   18686.68   1236\n",
      "1    East Harlem South   16797.26   1101\n",
      "2  Morningside Heights   13029.79    764\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c698d7-68e3-48b6-89e1-60572706e99d",
   "metadata": {},
   "source": [
    "## Question 6. Largest tip\n",
    "\n",
    "For the passengers picked up in October 2019 in the zone\n",
    "named \"East Harlem North\" which was the drop off zone that had\n",
    "the largest tip?\n",
    "\n",
    "Note: it's `tip` , not `trip`\n",
    "\n",
    "We need the name of the zone, not the ID.\n",
    "\n",
    "- Yorkville West\n",
    "- JFK Airport\n",
    "- East Harlem North\n",
    "- East Harlem South"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2b01c6e6-a8af-47d9-9a18-d983810faf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT\n",
    "    zdo.\"Zone\",\n",
    "    MAX(tip_amount) as \"max_tip_amount\"\n",
    "FROM\n",
    "    green_tripdata t\n",
    "JOIN\n",
    "    zones zpu ON t.\"PULocationID\" = zpu.\"LocationID\"\n",
    "JOIN\n",
    "    zones zdo ON t.\"DOLocationID\" = zdo.\"LocationID\"\n",
    "WHERE\n",
    "    CAST(lpep_pickup_datetime AS DATE) >= '2019-10-01' AND\n",
    "    CAST(lpep_pickup_datetime AS DATE) < '2019-11-01' AND\n",
    "    zpu.\"Zone\" = 'East Harlem North'\n",
    "GROUP BY\n",
    "    zdo.\"Zone\"\n",
    "ORDER BY\n",
    "    MAX(tip_amount) DESC\n",
    "LIMIT 1;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "fead3d08-58d7-4fb8-9454-b68917faacf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(query, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "cf496362-85c4-4229-8f5d-18903c4b9019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Zone  max_tip_amount\n",
      "0  JFK Airport            87.3\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1477423d-34a9-4355-a733-403af86ada8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
